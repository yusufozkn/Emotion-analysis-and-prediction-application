{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VERONICA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, BertTokenizerFast\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path = 'yeni data Final/yeni_train.csv'\n",
    "test_path = 'yeni data Final/yeni_test.csv'\n",
    "tremodata_path = 'TREMODATA.xml'\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "train.rename(columns={'Sentence':'text', 'Label':'label'}, inplace=True)\n",
    "train.drop(['Unnamed: 0'], inplace=True, axis='columns')\n",
    "\n",
    "test = pd.read_csv(test_path)\n",
    "test.rename(columns={'Sentence':'text', 'Label':'label'}, inplace=True)\n",
    "test.drop(['Unnamed: 0'], inplace=True, axis='columns')\n",
    "\n",
    "\n",
    "tremodata = pd.read_xml(tremodata_path)\n",
    "tremodata = tremodata[tremodata['Condition'] == 'Consensus']\n",
    "tremodata.drop(['ID', 'OriginalEmotion', 'Condition', 'VoteDistribution'], axis='columns', inplace=True)\n",
    "tremodata.rename(columns={'Entry':'text', 'ValidatedEmotion':'label'}, inplace=True)\n",
    "tremodata = tremodata.reset_index(drop=True)\n",
    "\n",
    "frames = [train, test, tremodata]\n",
    "df = pd.concat(frames)\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text     label\n",
      "0  Sadece 1 Yýl içinde bunu gönderen kullanýcý ço...     merak\n",
      "1  Bunu ben keÅfetmiÅtim haha Ã§ok eÄlendim Å...     mutlu\n",
      "2  [adi] sevi?yorum. gerçekten istiyorum. ona oy ...       aþk\n",
      "3  sevgi gönderiyorum. bunu yaþadýðýn için çok üz...       aþk\n",
      "4                            üzgünüm, üzgün deðilim.     utanç\n",
      "5      Murat Ã§ok Ã¼zdÃ¼n beni aÄlayacaÄÄ±m Åimdi   Ã¼zgÃ¼n\n",
      "6  [i?si?m] hýzlý uyumak çok güzel. i?ki sarýþýn ...       aþk\n",
      "7           Oha ciddi olamazsÄ±n neden bu kadar geÃ§   surpriz\n",
      "8  Bunun ( £ ) pound cinsinden ne kadar olacaðýný...     merak\n",
      "9  Bu takÄ±m her gol yediÄinde kel kafalÄ± baÅk...  kÄ±zgÄ±n\n"
     ]
    }
   ],
   "source": [
    "#ilk 10 veriyi göster\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "aþk         5490\n",
      "Happy       4416\n",
      "utanç       4085\n",
      "Sadness     3612\n",
      "Fear        3349\n",
      "Anger       3307\n",
      "merak       3267\n",
      "Disgust     2798\n",
      "Surprise    1980\n",
      "mutlu        800\n",
      "Ã¼zgÃ¼n      800\n",
      "surpriz      800\n",
      "kÄ±zgÄ±n     800\n",
      "korku        800\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#label sayıları ve dağılımı\n",
    "print(df['label'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling concatenated dataframe\n",
    "for i in df.index:\n",
    "  if df.label.iloc[i] == 'surpriz' or df.label.iloc[i] == 'Surprise':\n",
    "    df.at[i, 'label'] = 'surprise'\n",
    "  elif df.label.iloc[i] == 'kızgın' or df.label.iloc[i] == 'Anger' or df.label.iloc[i] == 'kÄ±zgÄ±n':\n",
    "    df.at[i, 'label'] = 'anger'\n",
    "  elif df.label.iloc[i] == 'Happy' or df.label.iloc[i] == 'mutlu':\n",
    "    df.at[i, 'label'] = 'joy'\n",
    "  elif df.label.iloc[i] == 'üzgün' or df.label.iloc[i] == 'Sadness' or df.label.iloc[i] == 'Ã¼zgÃ¼n':\n",
    "    df.at[i, 'label'] = 'sadness'\n",
    "  elif df.label.iloc[i] == 'korku' or df.label.iloc[i] == 'Fear':\n",
    "    df.at[i, 'label'] = 'fear'\n",
    "  elif df.label.iloc[i] == 'Disgust':\n",
    "    df.at[i, 'label'] = 'disgust'\n",
    "  elif df.label.iloc[i] == 'merak':\n",
    "    df.at[i, 'label'] = 'curiosity'\n",
    "  elif df.label.iloc[i] == 'aşk' or df.label.iloc[i] == 'aþk':\n",
    "    df.at[i, 'label'] = 'love'\n",
    "  elif df.label.iloc[i] == 'utanç':\n",
    "    df.at[i, 'label'] = 'shame'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "love         5490\n",
       "joy          5216\n",
       "sadness      4412\n",
       "fear         4149\n",
       "anger        4107\n",
       "shame        4085\n",
       "curiosity    3267\n",
       "disgust      2798\n",
       "surprise     2780\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#duygu cesidi ve sayisi\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['curiosity', 'joy', 'love', 'shame', 'sadness', 'surprise',\n",
       "       'anger', 'fear', 'disgust'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sadece 1 Yýl içinde bunu gönderen kullanýcý ço...</td>\n",
       "      <td>curiosity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bunu ben keÅfetmiÅtim haha Ã§ok eÄlendim Å...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[adi] sevi?yorum. gerçekten istiyorum. ona oy ...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sevgi gönderiyorum. bunu yaþadýðýn için çok üz...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üzgünüm, üzgün deðilim.</td>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36299</th>\n",
       "      <td>Okuldan mezun olduğum an.</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36300</th>\n",
       "      <td>Biri bana bir işi nasıl yapmam gerektiğini söy...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36301</th>\n",
       "      <td>Park halindeki arabama çarptıklarında.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36302</th>\n",
       "      <td>Bardağımı başkasının kullanması.</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36303</th>\n",
       "      <td>Beklemediğim şeylerle karşılaşmak.</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text      label\n",
       "0      Sadece 1 Yýl içinde bunu gönderen kullanýcý ço...  curiosity\n",
       "1      Bunu ben keÅfetmiÅtim haha Ã§ok eÄlendim Å...        joy\n",
       "2      [adi] sevi?yorum. gerçekten istiyorum. ona oy ...       love\n",
       "3      sevgi gönderiyorum. bunu yaþadýðýn için çok üz...       love\n",
       "4                               üzgünüm, üzgün deðilim.       shame\n",
       "...                                                  ...        ...\n",
       "36299                         Okuldan mezun olduğum an.         joy\n",
       "36300  Biri bana bir işi nasıl yapmam gerektiğini söy...      anger\n",
       "36301            Park halindeki arabama çarptıklarında.       anger\n",
       "36302                  Bardağımı başkasının kullanması.     disgust\n",
       "36303                Beklemediğim şeylerle karşılaşmak.    surprise\n",
       "\n",
       "[36304 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess text\n",
    "def filter(text):\n",
    "    final_text = ''\n",
    "    for word in text.split():\n",
    "        if word.startswith('@'):\n",
    "            continue\n",
    "        elif word == 'RT':\n",
    "            continue\n",
    "        elif word[-3:] in ['com', 'org']:\n",
    "            continue\n",
    "        elif word.startswith('pic') or word.startswith('http') or word.startswith('www'):\n",
    "            continue\n",
    "        elif word.startswith('!') or word.startswith('&') or word.startswith('-'):\n",
    "            continue\n",
    "        else:\n",
    "            final_text += word+' '\n",
    "    return final_text\n",
    "\n",
    "df['text'] = df['text'].apply(filter)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'curiosity': 0,\n",
       " 'joy': 1,\n",
       " 'love': 2,\n",
       " 'shame': 3,\n",
       " 'sadness': 4,\n",
       " 'surprise': 5,\n",
       " 'anger': 6,\n",
       " 'fear': 7,\n",
       " 'disgust': 8}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labellarin index karsiligini yazdirma\n",
    "label2index = {label: i for i, label in enumerate(df.label.unique())}\n",
    "index2label = {i: label for i, label in enumerate(df.label.unique())}\n",
    "label2index\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting labels to numerical\n",
    "# 0: anger, 1: curiosity, 2: disgust, 3: fear, 4: joy, 5: love, 6: sadness, 7: shame, 8: surprise\n",
    "\n",
    "for i in df.index:\n",
    "    if df.label.iloc[i] == 'anger':\n",
    "      df.at[i, 'label'] = 0\n",
    "    elif df.label.iloc[i] == 'curiosity':\n",
    "      df.at[i, 'label'] = 1\n",
    "    elif df.label.iloc[i] == 'disgust':\n",
    "      df.at[i, 'label'] = 2\n",
    "    elif df.label.iloc[i] == 'fear':\n",
    "      df.at[i, 'label'] = 3\n",
    "    elif df.label.iloc[i] == 'joy':\n",
    "      df.at[i, 'label'] = 4\n",
    "    elif df.label.iloc[i] == 'love':\n",
    "      df.at[i, 'label'] = 5\n",
    "    elif df.label.iloc[i] == 'sadness':\n",
    "      df.at[i, 'label'] = 6\n",
    "    elif df.label.iloc[i] == 'shame':\n",
    "      df.at[i, 'label'] = 7\n",
    "    elif df.label.iloc[i] == 'surprise':\n",
    "      df.at[i, 'label'] = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sadece 1 Yýl içinde bunu gönderen kullanýcý ço...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bunu ben keÅfetmiÅtim haha Ã§ok eÄlendim Å...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[adi] sevi?yorum. gerçekten istiyorum. ona oy ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sevgi gönderiyorum. bunu yaþadýðýn için çok üz...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üzgünüm, üzgün deðilim.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Murat Ã§ok Ã¼zdÃ¼n beni aÄlayacaÄÄ±m Åimdi</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[i?si?m] hýzlý uyumak çok güzel. i?ki sarýþýn ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oha ciddi olamazsÄ±n neden bu kadar geÃ§</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bunun ( £ ) pound cinsinden ne kadar olacaðýný...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bu takÄ±m her gol yediÄinde kel kafalÄ± baÅk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Sadece 1 Yýl içinde bunu gönderen kullanýcý ço...     1\n",
       "1  Bunu ben keÅfetmiÅtim haha Ã§ok eÄlendim Å...     4\n",
       "2  [adi] sevi?yorum. gerçekten istiyorum. ona oy ...     5\n",
       "3  sevgi gönderiyorum. bunu yaþadýðýn için çok üz...     5\n",
       "4                           üzgünüm, üzgün deðilim.      7\n",
       "5     Murat Ã§ok Ã¼zdÃ¼n beni aÄlayacaÄÄ±m Åimdi      6\n",
       "6  [i?si?m] hýzlý uyumak çok güzel. i?ki sarýþýn ...     5\n",
       "7          Oha ciddi olamazsÄ±n neden bu kadar geÃ§      8\n",
       "8  Bunun ( £ ) pound cinsinden ne kadar olacaðýný...     1\n",
       "9  Bu takÄ±m her gol yediÄinde kel kafalÄ± baÅk...     0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ilk 10 satiri yazdir\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of labels\n",
    "df.label.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle dataset \n",
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, test, valid\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\trandom_state = 42,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttest_size = 0.2,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tstratify = df['label'])\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\trandom_state = 42,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttest_size = 0.5,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tstratify = temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VERONICA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import pretrained tokenizer and model from https://huggingface.co/maymuni/bert-base-turkish-cased-emotion-analysis?text=I+like+you.+I+love+you\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"maymuni/bert-base-turkish-cased-emotion-analysis\")\n",
    "bert = AutoModel.from_pretrained(\"maymuni/bert-base-turkish-cased-emotion-analysis\",return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VERONICA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "# for validation set\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create DataLoaders\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      \n",
    "      super(Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "\n",
    "      # dense layer 3 (Output layer)\n",
    "      self.fc3 = nn.Linear(512,9)\n",
    "\n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "\n",
    "      x = self.fc1(cls_hs)\n",
    "\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "      x = self.fc3(x)\n",
    "\n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "# pass the pre-trained model to our define architecture\n",
    "model = Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VERONICA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98204504 1.2345065  1.44191242 0.97228081 0.77330458 0.73474499\n",
      " 0.91442335 0.9874541  1.45098921]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "cross_entropy  = nn.CrossEntropyLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>8,}  of  {:>8,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "      # Calculate elapsed time in minutes.\n",
    "      #elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "      # Report progress.\n",
    "      print('  Batch {:>8,}  of  {:>8,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Early Stopping Function\n",
    "def early_stopping(train_loss, validation_loss, min_delta, tolerance):\n",
    "\n",
    "    counter = 0\n",
    "    if (validation_loss - train_loss) > min_delta:\n",
    "        counter +=1\n",
    "        if counter >= tolerance:\n",
    "          return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n",
      "  Batch       50  of       908.\n",
      "  Batch      100  of       908.\n",
      "  Batch      150  of       908.\n",
      "  Batch      200  of       908.\n",
      "  Batch      250  of       908.\n",
      "  Batch      300  of       908.\n",
      "  Batch      350  of       908.\n",
      "  Batch      400  of       908.\n",
      "  Batch      450  of       908.\n",
      "  Batch      500  of       908.\n",
      "  Batch      550  of       908.\n",
      "  Batch      600  of       908.\n",
      "  Batch      650  of       908.\n",
      "  Batch      700  of       908.\n",
      "  Batch      750  of       908.\n",
      "  Batch      800  of       908.\n",
      "  Batch      850  of       908.\n",
      "  Batch      900  of       908.\n",
      "\n",
      "Evaluating...\n",
      "  Batch       50  of       114.\n",
      "  Batch      100  of       114.\n",
      "\n",
      "Training Loss: 0.944\n",
      "Validation Loss: 0.682\n",
      "\n",
      " Epoch 2 / 10\n",
      "  Batch       50  of       908.\n",
      "  Batch      100  of       908.\n",
      "  Batch      150  of       908.\n",
      "  Batch      200  of       908.\n",
      "  Batch      250  of       908.\n",
      "  Batch      300  of       908.\n",
      "  Batch      350  of       908.\n",
      "  Batch      400  of       908.\n",
      "  Batch      450  of       908.\n",
      "  Batch      500  of       908.\n",
      "  Batch      550  of       908.\n",
      "  Batch      600  of       908.\n",
      "  Batch      650  of       908.\n",
      "  Batch      700  of       908.\n",
      "  Batch      750  of       908.\n",
      "  Batch      800  of       908.\n",
      "  Batch      850  of       908.\n",
      "  Batch      900  of       908.\n",
      "\n",
      "Evaluating...\n",
      "  Batch       50  of       114.\n",
      "  Batch      100  of       114.\n",
      "\n",
      "Training Loss: 0.668\n",
      "Validation Loss: 0.563\n",
      "\n",
      " Epoch 3 / 10\n",
      "  Batch       50  of       908.\n",
      "  Batch      100  of       908.\n",
      "  Batch      150  of       908.\n",
      "  Batch      200  of       908.\n",
      "  Batch      250  of       908.\n",
      "  Batch      300  of       908.\n",
      "  Batch      350  of       908.\n",
      "  Batch      400  of       908.\n",
      "  Batch      450  of       908.\n",
      "  Batch      500  of       908.\n",
      "  Batch      550  of       908.\n",
      "  Batch      600  of       908.\n",
      "  Batch      650  of       908.\n",
      "  Batch      700  of       908.\n",
      "  Batch      750  of       908.\n",
      "  Batch      800  of       908.\n",
      "  Batch      850  of       908.\n",
      "  Batch      900  of       908.\n",
      "\n",
      "Evaluating...\n",
      "  Batch       50  of       114.\n",
      "  Batch      100  of       114.\n",
      "\n",
      "Training Loss: 0.586\n",
      "Validation Loss: 0.501\n",
      "\n",
      " Epoch 4 / 10\n",
      "  Batch       50  of       908.\n",
      "  Batch      100  of       908.\n",
      "  Batch      150  of       908.\n",
      "  Batch      200  of       908.\n",
      "  Batch      250  of       908.\n",
      "  Batch      300  of       908.\n",
      "  Batch      350  of       908.\n",
      "  Batch      400  of       908.\n",
      "  Batch      450  of       908.\n",
      "  Batch      500  of       908.\n",
      "  Batch      550  of       908.\n",
      "  Batch      600  of       908.\n",
      "  Batch      650  of       908.\n",
      "  Batch      700  of       908.\n",
      "  Batch      750  of       908.\n",
      "  Batch      800  of       908.\n",
      "  Batch      850  of       908.\n",
      "  Batch      900  of       908.\n",
      "\n",
      "Evaluating...\n",
      "  Batch       50  of       114.\n",
      "  Batch      100  of       114.\n",
      "\n",
      "Training Loss: 0.544\n",
      "Validation Loss: 0.454\n",
      "\n",
      " Epoch 5 / 10\n",
      "  Batch       50  of       908.\n",
      "  Batch      100  of       908.\n",
      "  Batch      150  of       908.\n",
      "  Batch      200  of       908.\n",
      "  Batch      250  of       908.\n",
      "  Batch      300  of       908.\n",
      "  Batch      350  of       908.\n",
      "  Batch      400  of       908.\n",
      "  Batch      450  of       908.\n",
      "  Batch      500  of       908.\n",
      "  Batch      550  of       908.\n",
      "  Batch      600  of       908.\n",
      "  Batch      650  of       908.\n",
      "  Batch      700  of       908.\n",
      "  Batch      750  of       908.\n",
      "  Batch      800  of       908.\n",
      "  Batch      850  of       908.\n",
      "  Batch      900  of       908.\n",
      "\n",
      "Evaluating...\n",
      "  Batch       50  of       114.\n",
      "  Batch      100  of       114.\n",
      "\n",
      "Training Loss: 0.519\n",
      "Validation Loss: 0.441\n",
      "\n",
      " Epoch 6 / 10\n",
      "  Batch       50  of       908.\n",
      "  Batch      100  of       908.\n",
      "  Batch      150  of       908.\n",
      "  Batch      200  of       908.\n",
      "  Batch      250  of       908.\n",
      "  Batch      300  of       908.\n",
      "  Batch      350  of       908.\n",
      "  Batch      400  of       908.\n",
      "  Batch      450  of       908.\n",
      "  Batch      500  of       908.\n",
      "  Batch      550  of       908.\n",
      "  Batch      600  of       908.\n",
      "  Batch      650  of       908.\n",
      "  Batch      700  of       908.\n",
      "  Batch      750  of       908.\n",
      "  Batch      800  of       908.\n",
      "  Batch      850  of       908.\n",
      "  Batch      900  of       908.\n",
      "\n",
      "Evaluating...\n",
      "  Batch       50  of       114.\n",
      "  Batch      100  of       114.\n",
      "\n",
      "Training Loss: 0.499\n",
      "Validation Loss: 0.414\n",
      "\n",
      " Epoch 7 / 10\n",
      "  Batch       50  of       908.\n",
      "  Batch      100  of       908.\n",
      "  Batch      150  of       908.\n",
      "  Batch      200  of       908.\n",
      "  Batch      250  of       908.\n",
      "  Batch      300  of       908.\n",
      "  Batch      350  of       908.\n",
      "  Batch      400  of       908.\n",
      "  Batch      450  of       908.\n",
      "  Batch      500  of       908.\n",
      "  Batch      550  of       908.\n",
      "  Batch      600  of       908.\n",
      "  Batch      650  of       908.\n",
      "  Batch      700  of       908.\n",
      "  Batch      750  of       908.\n",
      "  Batch      800  of       908.\n",
      "  Batch      850  of       908.\n",
      "  Batch      900  of       908.\n",
      "\n",
      "Evaluating...\n",
      "  Batch       50  of       114.\n",
      "  Batch      100  of       114.\n",
      "\n",
      "Training Loss: 0.482\n",
      "Validation Loss: 0.428\n",
      "\n",
      " Epoch 8 / 10\n",
      "  Batch       50  of       908.\n",
      "  Batch      100  of       908.\n",
      "  Batch      150  of       908.\n",
      "  Batch      200  of       908.\n",
      "  Batch      250  of       908.\n",
      "  Batch      300  of       908.\n",
      "  Batch      350  of       908.\n",
      "  Batch      400  of       908.\n",
      "  Batch      450  of       908.\n",
      "  Batch      500  of       908.\n",
      "  Batch      550  of       908.\n",
      "  Batch      600  of       908.\n",
      "  Batch      650  of       908.\n",
      "  Batch      700  of       908.\n",
      "  Batch      750  of       908.\n",
      "  Batch      800  of       908.\n",
      "  Batch      850  of       908.\n",
      "  Batch      900  of       908.\n",
      "\n",
      "Evaluating...\n",
      "  Batch       50  of       114.\n",
      "  Batch      100  of       114.\n",
      "\n",
      "Training Loss: 0.479\n",
      "Validation Loss: 0.399\n",
      "\n",
      " Epoch 9 / 10\n",
      "  Batch       50  of       908.\n",
      "  Batch      100  of       908.\n",
      "  Batch      150  of       908.\n",
      "  Batch      200  of       908.\n",
      "  Batch      250  of       908.\n",
      "  Batch      300  of       908.\n",
      "  Batch      350  of       908.\n",
      "  Batch      400  of       908.\n",
      "  Batch      450  of       908.\n",
      "  Batch      500  of       908.\n",
      "  Batch      550  of       908.\n",
      "  Batch      600  of       908.\n",
      "  Batch      650  of       908.\n",
      "  Batch      700  of       908.\n",
      "  Batch      750  of       908.\n",
      "  Batch      800  of       908.\n",
      "  Batch      850  of       908.\n",
      "  Batch      900  of       908.\n",
      "\n",
      "Evaluating...\n",
      "  Batch       50  of       114.\n",
      "  Batch      100  of       114.\n",
      "\n",
      "Training Loss: 0.469\n",
      "Validation Loss: 0.386\n",
      "\n",
      " Epoch 10 / 10\n",
      "  Batch       50  of       908.\n",
      "  Batch      100  of       908.\n",
      "  Batch      150  of       908.\n",
      "  Batch      200  of       908.\n",
      "  Batch      250  of       908.\n",
      "  Batch      300  of       908.\n",
      "  Batch      350  of       908.\n",
      "  Batch      400  of       908.\n",
      "  Batch      450  of       908.\n",
      "  Batch      500  of       908.\n",
      "  Batch      550  of       908.\n",
      "  Batch      600  of       908.\n",
      "  Batch      650  of       908.\n",
      "  Batch      700  of       908.\n",
      "  Batch      750  of       908.\n",
      "  Batch      800  of       908.\n",
      "  Batch      850  of       908.\n",
      "  Batch      900  of       908.\n",
      "\n",
      "Evaluating...\n",
      "  Batch       50  of       114.\n",
      "  Batch      100  of       114.\n",
      "\n",
      "Training Loss: 0.454\n",
      "Validation Loss: 0.389\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    # Train the model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    # Evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "\n",
    "    # Save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'early_save.pt')\n",
    "    \n",
    "    # Append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')\n",
    "\n",
    "    # Early stopping\n",
    "    if early_stopping(train_loss, valid_loss, min_delta=10, tolerance = 20):\n",
    "      print(\"We are at epoch:\", epoch)\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1849d2df8f0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, color='r')\n",
    "plt.plot(valid_losses, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the batch size for making predictions\n",
    "batch_size = 16\n",
    "\n",
    "# create a new data loader with reduced batch size\n",
    "test_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "# get predictions for test data with reduced batch size\n",
    "with torch.no_grad():\n",
    "  preds = []\n",
    "  for batch in test_dataloader:\n",
    "    batch = [r.to(device) for r in batch]\n",
    "    sent_id, mask, labels = batch\n",
    "    pred = model(sent_id, mask)\n",
    "    preds.append(pred.detach().cpu().numpy())\n",
    "\n",
    "# concatenate the predictions\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "\n",
    "# Labeling\n",
    "predicted_label = []\n",
    "for pred in preds:\n",
    "  predicted_label.append(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.90      0.85      0.87       411\n",
      "   curiosity       0.91      0.78      0.84       326\n",
      "     disgust       0.91      0.93      0.92       280\n",
      "        fear       0.88      0.91      0.90       415\n",
      "         joy       0.91      0.87      0.89       522\n",
      "        love       0.87      0.85      0.86       549\n",
      "     sadness       0.84      0.88      0.86       442\n",
      "       shame       0.77      0.84      0.80       408\n",
      "    surprise       0.84      0.91      0.88       278\n",
      "\n",
      "    accuracy                           0.87      3631\n",
      "   macro avg       0.87      0.87      0.87      3631\n",
      "weighted avg       0.87      0.87      0.87      3631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['anger', 'curiosity', 'disgust', 'fear', 'joy', 'love', 'sadness', 'shame', 'surprise']\n",
    "print(classification_report(test_y, predicted_label, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>349</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>259</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>376</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>455</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>467</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>391</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1    2    3    4    5    6    7    8\n",
       "row_0                                             \n",
       "0      349    3   12    5    5    2   27    2    6\n",
       "1        1  254    0    6    3   15    1   32   14\n",
       "2        6    0  259    5    2    0    6    1    1\n",
       "3        6    0    8  376    6    1   13    1    4\n",
       "4        2    1    1   10  455   21   18    3   11\n",
       "5        1    5    1    5    3  467    2   64    1\n",
       "6        9    5    1    7   18    1  391    1    9\n",
       "7       10    9    3   10    0   29    2  344    1\n",
       "8        3    1    1    1    8    2    8    1  253"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.crosstab(test_y, predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Emotions: {'korku': 0.49301663041114807, 'iğrenme': 0.41798365116119385, 'mutlu': 0.040350090712308884}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VERONICA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "C:\\Users\\VERONICA\\AppData\\Local\\Temp\\ipykernel_18360\\1498061613.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities = nn.functional.softmax(preds)\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "#Define predict function\n",
    "def predict_emotion(text):\n",
    "    tokenized = tokenizer.encode_plus(\n",
    "        text,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "\n",
    "    input_ids = tokenized['input_ids']\n",
    "    attention_mask = tokenized['attention_mask']\n",
    "\n",
    "    seq = torch.tensor(input_ids)\n",
    "    mask = torch.tensor(attention_mask)\n",
    "    seq = seq.unsqueeze(0)\n",
    "    mask = mask.unsqueeze(0)\n",
    "    preds = model(seq.to(device), mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    preds = torch.tensor(preds)\n",
    "    probabilities = nn.functional.softmax(preds)\n",
    "\n",
    "    # Get the top 3 emotions by probability\n",
    "    top3_emotions = heapq.nlargest(3, enumerate(probabilities[0]), key=lambda x: x[1])\n",
    "\n",
    "    # Get the names and probabilities of the top 3 emotions\n",
    "    top3_emotion_names = ['kızgın', 'üzgün', 'korku', 'iğrenme', 'mutlu', 'aşk', 'merak', 'utanç', 'şaşkınlık']\n",
    "    top3_emotion_probabilities = {top3_emotion_names[index]: float(prob) for index, prob in top3_emotions}\n",
    "\n",
    "    return top3_emotion_probabilities\n",
    "\n",
    "#Usage example\n",
    "top3_probabilities = predict_emotion(\"\")\n",
    "print(\"Top 3 Emotions:\", top3_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VERONICA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "C:\\Users\\VERONICA\\AppData\\Local\\Temp\\ipykernel_18360\\1498061613.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities = nn.functional.softmax(preds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mutlu': 0.7368144989013672,\n",
       " 'aşk': 0.2420353889465332,\n",
       " 'utanç': 0.01582074910402298}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "def get_prediction(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    return probs\n",
    "\n",
    "predict_emotion('çok mutluyum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeli kaydetme\n",
    "torch.save(model.state_dict(), 'model_Final_son.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer_Final_son\\\\tokenizer_config.json',\n",
       " 'tokenizer_Final_son\\\\special_tokens_map.json',\n",
       " 'tokenizer_Final_son\\\\vocab.txt',\n",
       " 'tokenizer_Final_son\\\\added_tokens.json',\n",
       " 'tokenizer_Final_son\\\\tokenizer.json')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeli kaydet\n",
    "tokenizer.save_pretrained('tokenizer_Final_son')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VERONICA\\AppData\\Local\\Temp\\ipykernel_18360\\1498061613.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities = nn.functional.softmax(preds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mutlu': 0.783873438835144,\n",
       " 'aşk': 0.20268450677394867,\n",
       " 'utanç': 0.008600687608122826}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cumle ile modeli test edelim\n",
    "model = Arch(bert)\n",
    "model.load_state_dict(torch.load('model_Final_son.pt'))\n",
    "model = model.to(device)\n",
    "\n",
    "predict_emotion('çok mutluyum')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
